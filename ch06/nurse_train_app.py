import os, io, json, ast, re, time, hashlib, tempfile, random
from glob import glob
from pathlib import Path
from typing import List, Dict, Optional, Tuple

import numpy as np
import pandas as pd
from numpy.linalg import norm

import streamlit as st
from streamlit_chat import message
from openai import OpenAI

# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(page_title="ê°„í˜¸ì‚¬ êµìœ¡ìš© ì±—ë´‡ (Excel RAG + Coach)", page_icon="ğŸ©º", layout="wide")

OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY"))
if not OPENAI_API_KEY:
    st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()
client = OpenAI(api_key=OPENAI_API_KEY)

CHAT_MODEL = "gpt-4o-mini"
EMBED_OPTIONS = ["text-embedding-3-small", "text-embedding-3-large"]
DEFAULT_EMBED = "text-embedding-3-large"
DATA_DIR = "./data"
os.makedirs(DATA_DIR, exist_ok=True)

BASE_DIR = Path(__file__).resolve().parent
XLS_CANDIDATES = [
    BASE_DIR / "ê°„í˜¸ì‚¬êµìœ¡_ì§ˆì˜ì‘ë‹µìë£Œ_ê·¼ë¬´ì§€ë³„.xlsx",
    BASE_DIR / "assets/ê°„í˜¸ì‚¬êµìœ¡_ì§ˆì˜ì‘ë‹µìë£Œ_ê·¼ë¬´ì§€ë³„.xlsx",
]

# ---- Session state defaults (í•­ìƒ ìµœìš°ì„ ìœ¼ë¡œ ì‹¤í–‰) ----
def _init_state():
    defaults = {
        "excel_df": None,
        "last_topk": None,
        "last_topk_source": "",
        "context_cols": [],
        "answer_col": None,
        "catalog": None,
        "active_sheet": None,
        "revealed_quiz": False,
        "revealed_coach": False,
        "draft_text": "",
        "filter_sig": "",
        "case_order": [],
        "case_pos": -1,
        "coaching_text": "",
        "ward_quiz": "ì „ì²´",
        "ward_coach": "ì „ì²´",
        "preset_to_filter": None,
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v
_init_state()

# =========================
# ìœ í‹¸
# =========================
def md5_of_bytes(b: bytes) -> str:
    m = hashlib.md5(); m.update(b); return m.hexdigest()

def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:
    da, db = norm(a), norm(b)
    return float(np.dot(a, b) / (da * db)) if (da and db) else 0.0

def to_np(e): return np.array(e, dtype=np.float32)

def safe_parse_embedding(x):
    try: return json.loads(x)
    except Exception: return ast.literal_eval(x)

@st.cache_data
def _load_bytes(path: str) -> bytes:
    with open(path, "rb") as f:
        return f.read()

# --- ì •ë‹µ í‚¤ì›Œë“œ & ì»¨í…ìŠ¤íŠ¸ ë³´í˜¸ ---
ANSWER_TOKENS = ["í‘œì¤€", "ëª¨ë²”", "ì •ë‹µ", "answer", "response"]

def strip_answer_from_context(text: str) -> str:
    """ë¼ë²¨ ì•ˆì— ì •ë‹µ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ í•´ë‹¹ ë¸”ë¡ ì œê±°"""
    if not text: return text
    pat = r"\[(?:[^]]*(?:%s)[^]]*)\]\s*[^|]*\s*(?:\|\s*)?" % "|".join(map(re.escape, ANSWER_TOKENS))
    return re.sub(pat, "", text, flags=re.IGNORECASE)

# --- ê·¼ë¬´ì§€ ì •ê·œí™” & ì‹œíŠ¸ëª…â†’ê·¼ë¬´ì§€ ---
WARD_CANON = ["ë³‘ë™ë¶„ë§Œì‹¤", "ì™¸ë˜", "ì‘ê¸‰ì‹¤", "ìˆ˜ìˆ ì‹¤", "ì‹ ìƒì•„ë¶€ì„œ"]

def _flat(s: object) -> str:
    """ë¹„ë¬¸ì/NaNë„ ì•ˆì „í•˜ê²Œ ì†Œë¬¸ì+ê³µë°±ì œê±° ë¬¸ìì—´ë¡œ ë³€í™˜"""
    if s is None:
        return ""
    try:
        s = str(s)
    except Exception:
        s = ""
    s = s.strip()
    if s.lower() in ("nan", "none", ""):
        return ""
    return re.sub(r"\s+", "", s.lower())

def normalize_ward(s: object) -> str:
    f = _flat(s)
    if not f:
        return "ê³µí†µ"
    if "ë¶„ë§Œ" in f or "ë³‘ë™" in f:
        return "ë³‘ë™ë¶„ë§Œì‹¤"
    if "ì™¸ë˜" in f:
        return "ì™¸ë˜"
    if "ì‘ê¸‰" in f or f == "er":
        return "ì‘ê¸‰ì‹¤"
    if "ìˆ˜ìˆ " in f or f == "or":
        return "ìˆ˜ìˆ ì‹¤"
    if "ì‹ ìƒì•„" in f or "nicu" in f or "ì†Œì•„" in f:
        return "ì‹ ìƒì•„ë¶€ì„œ"
    return s.strip() if isinstance(s, str) and s.strip() else "ê³µí†µ"

def ward_from_sheet(sheet_name: str) -> str:
    """ì‹œíŠ¸ ì´ë¦„ì—ì„œ ê·¼ë¬´ì§€ ì¶”ë¡ """
    return normalize_ward(sheet_name)

def reset_reveal_flags():
    st.session_state["revealed_quiz"] = False
    st.session_state["revealed_coach"] = False

# =========================
# ì„ë² ë”©(ìë™ ì°¨ì› ê°ì§€)
# =========================
EMBED_MODEL = DEFAULT_EMBED
EMBED_DIM: Optional[int] = None

def get_embedding(text: str) -> List[float]:
    global EMBED_DIM, EMBED_MODEL
    txt = (text or "").strip()
    if txt:
        resp = client.embeddings.create(model=EMBED_MODEL, input=txt)
        vec = resp.data[0].embedding
        if EMBED_DIM is None:
            EMBED_DIM = len(vec)  # small=1536, large=3072
        return vec
    else:
        if EMBED_DIM is None:
            resp = client.embeddings.create(model=EMBED_MODEL, input="a")
            EMBED_DIM = len(resp.data[0].embedding)
        return [0.0] * EMBED_DIM

# =========================
# ì—‘ì…€ â†’ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
# =========================
def guess_columns(df: pd.DataFrame) -> Tuple[List[str], Optional[str]]:
    cols = df.columns.tolist()
    answer_candidates = [c for c in cols if any(k in str(c) for k in ANSWER_TOKENS)]
    answer_col = answer_candidates[0] if answer_candidates else (cols[0] if cols else None)

    context_cols = []
    for c in cols:
        if c == answer_col: 
            continue
        if any(k in str(c) for k in ANSWER_TOKENS):
            continue
        if df[c].dtype == object:
            text_ratio = (df[c].astype(str).str.len() > 0).mean()
            if text_ratio > 0.3:
                context_cols.append(c)
    if not context_cols:
        context_cols = [c for c in cols if c != answer_col and not any(k in str(c) for k in ANSWER_TOKENS)][:3]
    return context_cols, answer_col

def build_context_row(row: pd.Series, context_cols: List[str], answer_col: Optional[str]) -> Dict[str, str]:
    parts = []
    for c in context_cols:
        if answer_col and c == answer_col:  # ì•ˆì „ì¥ì¹˜
            continue
        if any(k in str(c) for k in ANSWER_TOKENS):  # ì•ˆì „ì¥ì¹˜
            continue
        val = str(row.get(c, "") or "").strip()
        if val:
            parts.append(f"[{c}] {val}")
    context_text = " | ".join(parts) if parts else str(row.to_dict())
    context_text = strip_answer_from_context(context_text)  # í˜¹ì‹œ ì„ì—¬ ë“¤ì–´ì˜¨ ê²½ìš° ì œê±°
    answer_text = str(row.get(answer_col, "") or "").strip() if answer_col else ""
    return {"context": context_text, "answer": answer_text}

# =========================
# ê¸ˆê¸° í‘œí˜„ ì‹œíŠ¸
# =========================
def load_forbidden_sheet(xls_bytes: bytes) -> pd.DataFrame:
    try:
        xl = pd.ExcelFile(io.BytesIO(xls_bytes))
        if "ê¸ˆê¸°í‘œí˜„" not in xl.sheet_names:
            return pd.DataFrame(columns=["ê¸ˆê¸°í‘œí˜„","ì´ìœ ","ëŒ€ì²´ë¬¸êµ¬"])
        df = xl.parse("ê¸ˆê¸°í‘œí˜„").fillna("")
        needed = ["ê¸ˆê¸°í‘œí˜„","ì´ìœ ","ëŒ€ì²´ë¬¸êµ¬"]
        for n in needed:
            if n not in df.columns: df[n] = ""
        return df[needed]
    except Exception:
        return pd.DataFrame(columns=["ê¸ˆê¸°í‘œí˜„","ì´ìœ ","ëŒ€ì²´ë¬¸êµ¬"])

def forbidden_as_prompt(df_forb: pd.DataFrame) -> str:
    if df_forb is None or df_forb.empty: return ""
    items = []
    for _, r in df_forb.iterrows():
        items.append(f"- ê¸ˆê¸°: {r['ê¸ˆê¸°í‘œí˜„']} | ì´ìœ : {r['ì´ìœ ']} | ëŒ€ì²´: {r['ëŒ€ì²´ë¬¸êµ¬']}")
    return "ë‹¤ìŒ ê¸ˆê¸° í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì œì‹œëœ ëŒ€ì²´ ë¬¸êµ¬ë¥¼ ì°¸ê³ í•˜ì„¸ìš”:\n" + "\n".join(items)

# =========================
# ì„ë² ë”© ìºì‹œ êµ¬ì¶•/ë¡œë“œ (ì—‘ì…€ ê¸°ë°˜)
# =========================
def build_or_load_embeddings_from_excel(
    xls_bytes: bytes,
    sheet_name: Optional[str],
    context_cols: List[str],
    answer_col: Optional[str],
    embed_model_name: str
) -> pd.DataFrame:
    file_md5 = md5_of_bytes(xls_bytes)
    context_cols = [c for c in context_cols if c != answer_col and not any(k in str(c) for k in ANSWER_TOKENS)]
    columns_sig = json.dumps({"context": context_cols, "answer": answer_col}, ensure_ascii=False, sort_keys=True)
    cache_name = f"embed__{embed_model_name}__{file_md5}__{(sheet_name or 'all') }__{md5_of_bytes(columns_sig.encode())}.csv"
    cache_path = os.path.join(DATA_DIR, cache_name)

    if os.path.isfile(cache_path):
        st.info(f"ğŸ“¦ ìºì‹œ ë¡œë“œ: {os.path.basename(cache_path)}")
        df = pd.read_csv(cache_path)
        df["embedding"] = df["embedding"].apply(safe_parse_embedding)
        return df

    xl = pd.ExcelFile(io.BytesIO(xls_bytes))
    sheets = [sheet_name] if (sheet_name and sheet_name in xl.sheet_names) else xl.sheet_names

    rows = []
    for sh in sheets:
        ward_from_this_sheet = ward_from_sheet(sh)  # â–¶ ì‹œíŠ¸ëª… ê¸°ë°˜ ë¶„ë¥˜
        tdf = xl.parse(sh).fillna("")
        for ridx, row in tdf.iterrows():
            built = build_context_row(row, context_cols, answer_col)
            context, answer = built["context"], built["answer"]
            context = strip_answer_from_context(context)
            emb = get_embedding(context)
            rows.append({
                "sheet": sh,
                "row_index": ridx,
                "context": context,
                "answer": answer,
                "ward": ward_from_this_sheet,
                "embedding": emb
            })
            if (ridx % 20) == 19: time.sleep(0.03)

    df = pd.DataFrame(rows, columns=["sheet","row_index","context","answer","ward","embedding"])
    tmp = df.copy(); tmp["embedding"] = tmp["embedding"].apply(json.dumps)
    tmp.to_csv(cache_path, index=False, encoding="utf-8-sig")
    st.success(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ â†’ {os.path.basename(cache_path)}")
    return df

@st.cache_data(show_spinner=True)
def load_precomputed_embeddings(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    df["embedding"] = df["embedding"].apply(safe_parse_embedding)
    return df

def pick_precomputed_cache(embed_model: str) -> Optional[str]:
    pattern = os.path.join(DATA_DIR, f"embed__{embed_model}__*.csv")
    candidates = glob(pattern)
    if not candidates:
        return None
    candidates.sort(key=lambda p: os.path.getmtime(p), reverse=True)
    return candidates[0]

# =========================
# ì¹´íƒˆë¡œê·¸(ìë™ ì œì‹œ)
# =========================
TITLE_KEYS = ["í‰ê°€í•­ëª©","í•­ëª©","ì£¼ì œ","ì¼€ì´ìŠ¤","ì§ˆë¬¸","ì œëª©","ì¹´í…Œê³ ë¦¬"]

def build_catalog_from_embed(df_embed: pd.DataFrame) -> pd.DataFrame:
    titles, rows, seen = [], [], set()
    for _, r in df_embed.iterrows():
        text = r["context"]
        m = re.search(r"\[(í‰ê°€í•­ëª©|í•­ëª©|ì£¼ì œ|ì¼€ì´ìŠ¤|ì§ˆë¬¸|ì œëª©|ì¹´í…Œê³ ë¦¬)\]\s*([^|\n]+)", text)
        if m:
            title = m.group(2).strip()[:40]
        else:
            ans = (r.get("answer") or "")[:40]
            title = ans or (text[:40] if text else f"Row {r['row_index']}")
        if title in seen:
            continue
        seen.add(title)
        titles.append(title); rows.append(int(r["row_index"]))
    return pd.DataFrame({"case_title": titles, "row_index": rows})

def render_case_shelf(catalog: pd.DataFrame, label="ì¶”ì²œ ì¼€ì´ìŠ¤", max_items: int = 18) -> Optional[int]:
    if catalog is None or catalog.empty:
        return None
    st.markdown(f"#### ğŸ“š {label}")
    show = catalog.head(max_items).reset_index(drop=True)
    cols = st.columns(3)
    chosen: Optional[int] = None
    for i, row in show.iterrows():
        with cols[i % 3]:
            if st.button("ğŸ”¹ " + str(row["case_title"]), key=f"case_{label}_{i}"):
                chosen = int(row["row_index"])
    with st.expander("ì „ì²´ ëª©ë¡ ë³´ê¸°"):
        st.dataframe(catalog, use_container_width=True)
    return chosen

def select_case_by_row(df_embed: pd.DataFrame, sheet: str, row_index: int) -> pd.DataFrame:
    sel = df_embed[(df_embed["sheet"]==sheet) & (df_embed["row_index"]==row_index)]
    if len(sel)==0:
        sel = df_embed[df_embed["row_index"]==row_index]
    if len(sel)==0:
        sel = df_embed.head(1)
    return sel.head(1).reset_index(drop=True)

# =========================
# ê²€ìƒ‰ & LLM í˜¸ì¶œ
# =========================
def search_top_k(df: pd.DataFrame, query: str, k: int = 3) -> pd.DataFrame:
    q_emb = to_np(get_embedding(query))
    if "_np_emb" not in df.columns:
        df["_np_emb"] = df["embedding"].apply(to_np)
    sims = df["_np_emb"].apply(lambda v: cosine_sim(v, q_emb))
    return df.assign(similarity=sims).sort_values("similarity", ascending=False).head(k).reset_index(drop=True)

def call_llm(messages: List[Dict[str, str]], max_output_tokens: int = 900, temperature: float = 0.3) -> str:
    resp = client.responses.create(
        model=CHAT_MODEL,
        input=messages,
        max_output_tokens=max_output_tokens,
        temperature=temperature,
    )
    try:
        return (resp.output_text or "").strip()
    except Exception:
        return "[ì¶œë ¥ íŒŒì‹± ì‹¤íŒ¨]"

# =========================
# í”„ë¡¬í”„íŠ¸
# =========================
def make_messages_for_answer(topk: pd.DataFrame, user_query: str, workplace: str, forb_prompt: str) -> List[Dict[str, str]]:
    def trim(s: str, n: int = 1000): return s if len(s) <= n else s[:n] + " â€¦"
    docs = []
    for i, r in topk.iterrows():
        docs.append(
            f"[doc {i+1}] sheet={r['sheet']} | row={r['row_index']} | sim={r.get('similarity',1.0):.4f}\n"
            f"ì»¨í…ìŠ¤íŠ¸: {trim(r['context'])}\n"
            f"í‘œì¤€ì‘ë‹µ: {trim(r['answer'])}"
        )
    joined = "\n\n".join(docs)
    system = (
        "ë‹¹ì‹ ì€ ê°„í˜¸ì‚¬ ì§ë¬´ êµìœ¡ìš© í•œêµ­ì–´ ì¡°ì–¸ìì…ë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì™€ í‘œì¤€ì‘ë‹µë§Œ ê·¼ê±°ë¡œ, "
        "í˜„ì¥ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì ˆì°¨/ë¬¸êµ¬/ì£¼ì˜ì‚¬í•­ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. "
        f"ê·¼ë¬´ì§€ëŠ” {workplace}ì´ë©°, í•´ë‹¹ í™˜ê²½ì— ë§ëŠ” ì–´íœ˜/í†¤ì„ ì‚¬ìš©í•˜ì„¸ìš”. "
        + (("\n" + forb_prompt) if forb_prompt else "")
    )
    user = (
        f"ì§ˆë¬¸: {user_query}\n\n"
        f"ì°¸ê³  ìë£Œ:\n{joined}\n\n"
        "ì¶œë ¥ í˜•ì‹:\n"
        "1) í•µì‹¬ ìš”ì§€ bullet\n2) ë‹¨ê³„/ìš°ì„ ìˆœìœ„\n3) ê¶Œì¥ ë§í•˜ê¸° ì˜ˆì‹œ\n4) ë§ˆì§€ë§‰ ì¤„ ê·¼ê±°: [doc n], sheet/row"
    )
    return [{"role":"system","content":system},{"role":"user","content":user}]

def make_messages_for_quiz(top1: pd.Series, user_answer: str, workplace: str, forb_prompt: str) -> List[Dict[str, str]]:
    system = (
        "ë‹¹ì‹ ì€ ê°„í˜¸ì‚¬ êµìœ¡ í‰ê°€ìì…ë‹ˆë‹¤. í‘œí˜„ì´ ë‹¬ë¼ë„ ì˜ë¯¸ê°€ ë™ë“±í•˜ë©´ ì •ë‹µìœ¼ë¡œ ì¸ì •í•˜ì„¸ìš”. "
        "í™˜ìì•ˆì „/ì ˆì°¨ ì •í™•ì„±/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì ì ˆì„± ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ê³ , ê¸ˆê¸° í‘œí˜„ì€ ê°ì í•˜ì„¸ìš”. "
        f"ê·¼ë¬´ì§€ëŠ” {workplace} ìƒí™©ì…ë‹ˆë‹¤. " + (("\n" + forb_prompt) if forb_prompt else "") +
        "\në°˜ë“œì‹œ í•œêµ­ì–´ë¡œ í”¼ë“œë°±í•˜ì„¸ìš”."
    )
    user = f"""
[ì»¨í…ìŠ¤íŠ¸]
{top1['context']}

[í›ˆë ¨ìƒ ë‹µë³€]
{user_answer}

[í‘œì¤€ì‘ë‹µ(ê·¼ê±°)]
{top1['answer']}

ìš”êµ¬ì‚¬í•­:
- ì¥ë‹¨ì  í”¼ë“œë°±(í•­ëª©ë³„)
- ì ìˆ˜(0~100)ì™€ ê·¼ê±°
- ê°œì„  ì˜ˆì‹œ ë‹µë³€(í˜„ì¥í˜•)
- ë§ˆì§€ë§‰ ì¤„: ê·¼ê±° í‘œê¸°(sheet/row)
"""
    return [{"role":"system","content":system},{"role":"user","content":user}]

def make_messages_for_coach(top1: pd.Series, user_answer: str, workplace: str, tone: str, forb_prompt: str) -> List[Dict[str, str]]:
    system = (
        "ë‹¹ì‹ ì€ ì„ìƒ í˜„ì¥ì—ì„œ ê°„í˜¸ì‚¬ì˜ í™˜ì ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì„ ì½”ì¹­í•˜ëŠ” í•œêµ­ì–´ ì½”ì¹˜ì…ë‹ˆë‹¤. "
        "í‘œí˜„ì´ ë‹¬ë¼ë„ ì˜ë¯¸ê°€ ë™ë“±í•˜ë©´ í—ˆìš©í•˜ë˜, í™˜ìì•ˆì „ê³¼ ì˜ˆì ˆ(ì¡´ì¹­/ê²½ì²­/ëª…ë£Œì„±)ì„ ìµœìš°ì„  ê¸°ì¤€ìœ¼ë¡œ ì§€ë„í•˜ì„¸ìš”. "
        f"ê·¼ë¬´ì§€ëŠ” {workplace}ì´ë©° í•´ë‹¹ í™˜ê²½ì— ë§ëŠ” ì–´íœ˜/í†¤ì„ ì‚¬ìš©í•˜ì„¸ìš”. " +
        (("\n" + forb_prompt) if forb_prompt else "") + "\nì¶”ì¸¡ì€ ê¸ˆì§€í•˜ë©° ì œê³µ ìë£Œ ë²”ìœ„ì—ì„œë§Œ ì§€ë„í•©ë‹ˆë‹¤."
    )
    user = f"""
[ì»¨í…ìŠ¤íŠ¸]
{top1['context']}

[í›ˆë ¨ìƒ ì´ˆì•ˆ]
{user_answer}

[í‘œì¤€ì‘ë‹µ(ê·¼ê±°)]
{top1['answer']}

ìš”êµ¬ì‚¬í•­(í•œêµ­ì–´ë¡œ {tone}):
1) ì˜í•œ ì (1~3ê°œ) â€” ìœ ì§€ ì´ìœ 
2) ê°œì„  í¬ì¸íŠ¸(2~4ê°œ) â€” ì™œ/ì–´ë–»ê²Œ
3) ëª¨ë²” ë‹µì•ˆ(Baseline Script) â€” 2~4ë¬¸ì¥
4) ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸(Variants)
   - ì§§ê³  ì •ì¤‘í•œ(1~2ë¬¸ì¥)
   - ê³µê° ê°•í™”(2~3ë¬¸ì¥)
   - ê¸´ê¸‰/ì•ˆì „ ìš°ì„ (í•„ìš”ì‹œ, 1~2ë¬¸ì¥)
5) ì•ˆì „Â·ì˜ˆì ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸(3~6ê°œ) â€” ë°˜ë“œì‹œ/ê¸ˆê¸° êµ¬ë¶„
6) ì—°ìŠµ í”„ë¡¬í”„íŠ¸(1~2ê°œ)
7) ë§ˆì§€ë§‰ ì¤„ ê·¼ê±°: sheet={top1['sheet']}, row={top1['row_index']}
"""
    return [{"role":"system","content":system},{"role":"user","content":user}]

# =========================
# TTS
# =========================
def synthesize_tts(text: str) -> Optional[str]:
    txt = (text or "").strip()
    if not txt: return None
    try:
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        tmp_path = Path(tmp.name); tmp.close()
        with client.audio.speech.with_streaming_response.create(
            model="gpt-4o-mini-tts", voice="alloy", input=txt
        ) as resp:
            resp.stream_to_file(tmp_path)
        return str(tmp_path)
    except Exception as e:
        st.warning(f"TTS ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# =========================
# ì‚¬ì´ë“œë°”
# =========================
with st.sidebar:
    st.markdown("### âš™ï¸ ì„¤ì •")
    EMBED_MODEL = st.selectbox("ì„ë² ë”© ëª¨ë¸", EMBED_OPTIONS, index=EMBED_OPTIONS.index(DEFAULT_EMBED))
    mode = st.radio("ëª¨ë“œ ì„ íƒ", ["ì§ˆë¬¸(í•™ìŠµ)", "í€´ì¦ˆ(í‰ê°€)", "ì½”ì¹˜(ì§€ë„)"], index=2)
    workplace_display = st.selectbox("ê·¼ë¬´ì§€ í”„ë¦¬ì…‹(í†¤)", WARD_CANON, index=2)
    workplace = workplace_display
    st.caption("í”„ë¦¬ì…‹ì€ ë‹µë³€ í†¤/ìš°ì„ ìˆœìœ„ë¥¼ ë°”ê¾¸ë©°, í•„ìš” ì‹œ ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ë³‘ë™ í•„í„°ì—ë„ ì ìš©í•˜ì„¸ìš”.")
    if st.button("â†‘ í”„ë¦¬ì…‹ì„ ë³‘ë™ í•„í„°ì— ì ìš©"):
        st.session_state["preset_to_filter"] = workplace_display
        st.success(f"í”„ë¦¬ì…‹ '{workplace_display}'ì„(ë¥¼) í•„í„°ì— ì ìš©í•©ë‹ˆë‹¤.")
    st.divider()

    uploaded = st.file_uploader("ì—‘ì…€ ì—…ë¡œë“œ (.xlsx) â€” ì—…ë¡œë“œ ì—†ìœ¼ë©´ ê¸°ë³¸ íŒŒì¼ ìë™ ì‚¬ìš©", type=["xlsx"])
    sheet_input = st.text_input("ì‚¬ìš©í•  ì‹œíŠ¸ëª…(ë¹„ìš°ë©´ ì „ì²´ ì‹œíŠ¸)", value="")
    use_forbidden = st.toggle("ê¸ˆê¸° í‘œí˜„ ì‹œíŠ¸(ê¸ˆê¸°í‘œí˜„) ì‚¬ìš©", value=True)

    # ---- ìºì‹œ/ì„ë² ë”© ì •ë¦¬ ----
    with st.expander("ğŸ§¹ ìºì‹œ/ì„ë² ë”© ì •ë¦¬"):
        if st.button("ì„ë² ë”© CSV ì‚­ì œ (data/embed__*.csv)"):
            removed = 0
            for p in glob(os.path.join(DATA_DIR, "embed__*.csv")):
                try:
                    os.remove(p); removed += 1
                except Exception as e:
                    st.warning(f"ì‚­ì œ ì‹¤íŒ¨: {p} ({e})")
            st.cache_data.clear()
            st.success(f"ì„ë² ë”© CSV {removed}ê°œ ì‚­ì œ ë° Streamlit cache ì´ˆê¸°í™” ì™„ë£Œ")
            st.stop()

# =========================
# ê¸°ë³¸ ì—‘ì…€ ë¡œë“œ
# =========================
if uploaded is None:
    xls_path = next((p for p in XLS_CANDIDATES if p.exists()), XLS_CANDIDATES[0])
    try:
        xls_bytes = _load_bytes(str(xls_path))
        st.info(f"ì—…ë¡œë“œ ì—†ìŒ â†’ ê¸°ë³¸ íŒŒì¼ ì‚¬ìš©: {xls_path.name}")
    except Exception as e:
        st.error(f"ê¸°ë³¸ ì—‘ì…€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—…ë¡œë“œí•˜ê±°ë‚˜ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”. ({e})"); st.stop()
else:
    xls_bytes = uploaded.getvalue()

# ê¸ˆê¸° ì‹œíŠ¸
forbidden_df = load_forbidden_sheet(xls_bytes) if use_forbidden else pd.DataFrame()
forb_prompt = forbidden_as_prompt(forbidden_df)

# =========================
# ì‚¬ì „ ê³„ì‚° ì„ë² ë”© ì‚¬ìš©(ìˆìœ¼ë©´)
# =========================
precomputed = pick_precomputed_cache(EMBED_MODEL)
if uploaded is None and st.session_state["excel_df"] is None and precomputed:
    st.session_state["excel_df"] = load_precomputed_embeddings(precomputed)
    st.success(f"ğŸ“¦ ì‚¬ì „ ê³„ì‚° ì„ë² ë”© ì‚¬ìš©: {os.path.basename(precomputed)}")

# =========================
# ë¯¸ë¦¬ë³´ê¸° & ì»¬ëŸ¼ ë§¤í•‘ (ì„ë² ë”© DFê°€ ì•„ì§ ì—†ì„ ë•Œë§Œ)
# =========================
if st.session_state["excel_df"] is None:
    try:
        preview_xl = pd.ExcelFile(io.BytesIO(xls_bytes))
        default_sheet = (sheet_input or preview_xl.sheet_names[0])
        st.session_state["active_sheet"] = default_sheet
        preview_df = preview_xl.parse(default_sheet).fillna("")
        st.write(f"**ì‹œíŠ¸:** {default_sheet} / **í–‰:** {len(preview_df)} / **ì—´:** {len(preview_df.columns)}")
        st.dataframe(preview_df.head(8), use_container_width=True)
    except Exception as e:
        st.error(f"ì—‘ì…€ ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {e}"); st.stop()

    st.subheader("ğŸ§© ì»¬ëŸ¼ ë§¤í•‘")
    cols = preview_df.columns.tolist()
    if not st.session_state["context_cols"] and not st.session_state["answer_col"]:
        g_ctx, g_ans = guess_columns(preview_df)
        st.session_state["context_cols"] = g_ctx
        st.session_state["answer_col"] = g_ans

    sel_ctx = st.multiselect("ì»¨í…ìŠ¤íŠ¸ë¡œ í•©ì¹  ì—´ë“¤", cols, default=[c for c in st.session_state["context_cols"] if c in cols])
    sel_ans = st.selectbox("í‘œì¤€ì‘ë‹µ(ì •ë‹µ) ì—´", ["<ì„ íƒ ì•ˆ í•¨>"] + cols,
                           index=(0 if (st.session_state["answer_col"] not in cols) else (cols.index(st.session_state["answer_col"]) + 1)))
    st.caption("â€» ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì •ë‹µ ì—´ì€ ìë™ ì œì™¸ë©ë‹ˆë‹¤.")

    if st.button("ì´ ë§¤í•‘ìœ¼ë¡œ ì„ë² ë”© ìºì‹œ ìƒì„±/ë¡œë“œ"):
        try:
            cleaned_ctx = [c for c in sel_ctx if c != sel_ans and not any(k in str(c) for k in ANSWER_TOKENS)]
            df_embed = build_or_load_embeddings_from_excel(
                xls_bytes=xls_bytes,
                sheet_name=(sheet_input or None) if sheet_input else None,  # ë¹ˆ ê°’ì´ë©´ ì „ì²´ ì‹œíŠ¸
                context_cols=cleaned_ctx if cleaned_ctx else [c for c in cols[:3] if c != sel_ans],
                answer_col=(None if sel_ans == "<ì„ íƒ ì•ˆ í•¨>" else sel_ans),
                embed_model_name=EMBED_MODEL
            )
            st.session_state["excel_df"] = df_embed
            st.session_state["context_cols"] = cleaned_ctx if cleaned_ctx else [c for c in cols[:3] if c != sel_ans]
            st.session_state["answer_col"] = (None if sel_ans == "<ì„ íƒ ì•ˆ í•¨>" else sel_ans)
            st.session_state["active_sheet"] = default_sheet
            st.success("ì„ë² ë”© ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!")
        except Exception as e:
            st.error(f"ì„ë² ë”© ì¤€ë¹„ ì‹¤íŒ¨: {e}")

df_embed = st.session_state["excel_df"]
if df_embed is None:
    st.info("ë¨¼ì € **ì„ë² ë”© ìºì‹œ ìƒì„±/ë¡œë“œ**ë¥¼ ì™„ë£Œí•˜ì„¸ìš”."); st.stop()

# --- ward_norm ìƒì„±: ward ì—†ê±°ë‚˜ ê³µí†µë¿ì´ë©´ ì‹œíŠ¸ëª…ìœ¼ë¡œ ê°•ì œ ì¬ë¶„ë¥˜
if "ward" in df_embed.columns:
    ward_source = df_embed["ward"]
else:
    ward_source = df_embed["sheet"].map(ward_from_sheet)
df_embed["ward_norm"] = ward_source.map(normalize_ward)

unique_wards = sorted([w for w in df_embed["ward_norm"].dropna().unique().tolist() if str(w).strip()])
if not unique_wards or set(unique_wards) == {"ê³µí†µ"}:
    df_embed["ward_norm"] = df_embed["sheet"].map(ward_from_sheet).map(normalize_ward)
    unique_wards = sorted([w for w in df_embed["ward_norm"].dropna().unique().tolist() if str(w).strip()])

# í”„ë¦¬ì…‹â†’í•„í„° ì ìš© ë²„íŠ¼ì„ ëˆŒë €ë‹¤ë©´ ë™ê¸°í™”
if st.session_state.get("preset_to_filter"):
    p = st.session_state.pop("preset_to_filter")
    if p in unique_wards:
        st.session_state["ward_quiz"] = p
        st.session_state["ward_coach"] = p

# ì¹´íƒˆë¡œê·¸
st.session_state["catalog"] = build_catalog_from_embed(df_embed)
catalog = st.session_state["catalog"]

st.title("ğŸ©º ê°„í˜¸ì‚¬ êµìœ¡ìš© ì±—ë´‡ (Excel RAG + Coach)")
st.caption(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë³‘ë™ ë¶„ë¥˜: {', '.join(unique_wards) if unique_wards else 'ì—†ìŒ(ì‹œíŠ¸ëª… í™•ì¸ í•„ìš”)'}")

# =========================
# ê³µí†µ ì¶œì œ/í•„í„°
# =========================
def get_filtered_catalog(_catalog: pd.DataFrame, ward_choice: str) -> pd.DataFrame:
    if (_catalog is not None) and (not _catalog.empty) and ward_choice and ward_choice != "ì „ì²´":
        idxs = set(df_embed.loc[df_embed["ward_norm"] == ward_choice, "row_index"].astype(int).tolist())
        return _catalog[_catalog["row_index"].isin(list(idxs))].reset_index(drop=True)
    return _catalog

def rebuild_order_if_needed(filtered: pd.DataFrame, shuffle: bool, ward_choice: str, mode_tag: str):
    sig = json.dumps({"ward": ward_choice, "shuffle": shuffle, "mode": mode_tag})
    if st.session_state["filter_sig"] != sig:
        st.session_state["filter_sig"] = sig
        order = filtered["row_index"].astype(int).tolist() if filtered is not None else []
        if shuffle: random.shuffle(order)
        st.session_state["case_order"] = order
        st.session_state["case_pos"] = -1
        st.session_state["last_topk"] = None
        reset_reveal_flags()

def next_case(filtered: pd.DataFrame):
    if filtered is None or filtered.empty: return
    if not st.session_state["case_order"]:
        st.session_state["case_order"] = filtered["row_index"].astype(int).tolist()
    st.session_state["case_pos"] = (st.session_state["case_pos"] + 1) % len(st.session_state["case_order"])
    ridx = st.session_state["case_order"][st.session_state["case_pos"]]
    sheet = st.session_state.get("active_sheet") or str(df_embed["sheet"].iloc[0])
    st.session_state["last_topk"] = select_case_by_row(df_embed, sheet, ridx)
    reset_reveal_flags()

def random_case(filtered: pd.DataFrame):
    if filtered is None or filtered.empty: return
    ridx = int(filtered.sample(1)["row_index"].iloc[0])
    sheet = st.session_state.get("active_sheet") or str(df_embed["sheet"].iloc[0])
    st.session_state["last_topk"] = select_case_by_row(df_embed, sheet, ridx)
    reset_reveal_flags()

def ensure_case_selected(filtered: pd.DataFrame):
    if st.session_state["last_topk"] is None and filtered is not None and not filtered.empty:
        random_case(filtered)

def show_case_header(top1: pd.Series, reveal_answer: bool):
    st.markdown("### ğŸ“„ ì¼€ì´ìŠ¤ ìš”ì•½")
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**ì»¨í…ìŠ¤íŠ¸**")
        st.write(top1["context"])  # ì»¨í…ìŠ¤íŠ¸ëŠ” ì •ë‹µ ì œê±°ë¨
    with c2:
        st.markdown("**í‘œì¤€ì‘ë‹µ**")
        if reveal_answer:
            st.success("ì •ë‹µ ê³µê°œ")
            st.write(top1["answer"])
        else:
            st.info("ì •ë‹µì€ ì œì¶œ í›„ ê³µê°œë©ë‹ˆë‹¤.")

# =========================
# ëª¨ë“œë³„ UI
# =========================
if mode == "ì§ˆë¬¸(í•™ìŠµ)":
    with st.form("ask_form", clear_on_submit=True):
        q = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 'í™˜ì í™•ì¸ ì ˆì°¨ëŠ”?')", "")
        send = st.form_submit_button("Send")
    if send and q.strip():
        topk = search_top_k(df_embed, q.strip(), k=3)
        st.session_state["last_topk"] = topk
        st.session_state["last_topk_source"] = "ask"  # â† ê²€ìƒ‰ì—ì„œ ì˜¨ ê²ƒ í‘œì‹œ(ì„ íƒì )
        msgs = make_messages_for_answer(topk, q.strip(), workplace, forb_prompt)
        ans = call_llm(msgs)
        message(q.strip(), is_user=True, key="ask_u_"+str(time.time()))
        message(ans, key="ask_b_"+str(time.time()))
    # ì•ˆì „í•œ Top-K í‘œ (ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ)
    with st.expander("ğŸ” ì‚¬ìš©ëœ ìë£Œ(Top-K)"):
        lt = st.session_state.get("last_topk")
        if isinstance(lt, pd.DataFrame) and not lt.empty:
            want = ["sheet", "row_index", "similarity", "context", "answer"]
            cols_show = [c for c in want if c in lt.columns]
            st.dataframe(lt[cols_show], use_container_width=True)
        else:
            st.caption("ì•„ì§ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

elif mode == "í€´ì¦ˆ(í‰ê°€)":
    ward_options = ["ì „ì²´"] + unique_wards
    opt_col1, opt_col2, opt_col3, opt_col4 = st.columns([2,1,1,2])
    with opt_col1:
        ward_choice = st.selectbox("ê·¼ë¬´ì§€(ë³‘ë™)ë¡œ í•„í„°", ward_options, index=0, key="ward_quiz")
    with opt_col2:
        btn_next = st.button("ë‹¤ìŒ ë¬¸ì œ")
    with opt_col3:
        btn_rand = st.button("ëœë¤ ì¶œì œ")
    with opt_col4:
        tiles = st.slider("ë²„íŠ¼ í‘œì‹œ ê°œìˆ˜", 6, 48, 18, 3)

    filtered_catalog = get_filtered_catalog(catalog, st.session_state.get("ward_quiz","ì „ì²´"))
    st.caption(f"ê°€ìš© ë¬¸í•­: {0 if filtered_catalog is None else len(filtered_catalog)}ê°œ")

    rebuild_order_if_needed(filtered_catalog, shuffle=False, ward_choice=st.session_state.get("ward_quiz","ì „ì²´"), mode_tag="quiz")

    if btn_next: next_case(filtered_catalog)
    if btn_rand: random_case(filtered_catalog)
    ensure_case_selected(filtered_catalog)

    chosen = render_case_shelf(filtered_catalog, label="ë‹¤ë¥¸ ì¼€ì´ìŠ¤ ì„ íƒ", max_items=tiles)
    if chosen is not None:
        sheet = st.session_state.get("active_sheet") or str(df_embed["sheet"].iloc[0])
        st.session_state["last_topk"] = select_case_by_row(df_embed, sheet, chosen)
        st.session_state["last_topk_source"] = "quiz_select"
        reset_reveal_flags()

    if st.session_state["last_topk"] is not None and len(st.session_state["last_topk"])>0:
        top1 = st.session_state["last_topk"].iloc[0]
        show_case_header(top1, reveal_answer=st.session_state["revealed_quiz"])

        st.caption("ì»¨í…ìŠ¤íŠ¸ë§Œ ë³´ê³  ë‹µí•´ë³´ì„¸ìš”. ì œì¶œ í›„ ì •ë‹µì´ ê³µê°œë©ë‹ˆë‹¤.")
        with st.form("quiz_form", clear_on_submit=False):
            user_answer = st.text_area("í›ˆë ¨ìƒ ë‹µë³€", height=180)
            btn_eval = st.form_submit_button("í‰ê°€ ìš”ì²­")
        if btn_eval:
            msgs = make_messages_for_quiz(top1, (user_answer or "").strip(), workplace, forb_prompt)
            feedback = call_llm(msgs)
            st.markdown("### ğŸ§ª í‰ê°€ ê²°ê³¼"); st.write(feedback)
            st.session_state["revealed_quiz"] = True
            with st.expander("ì •ë‹µ(í‘œì¤€ì‘ë‹µ) ë³´ê¸°", expanded=True):
                st.write(top1["answer"])
    else:
        st.warning("ì¼€ì´ìŠ¤ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ì„ë² ë”©ì„ ì¤€ë¹„í•´ ì£¼ì„¸ìš”.")

else:  # ì½”ì¹˜(ì§€ë„)
    ward_options = ["ì „ì²´"] + unique_wards
    opt_col1, opt_col2, opt_col3, opt_col4 = st.columns([2,1,1,2])
    with opt_col1:
        ward_choice = st.selectbox("ê·¼ë¬´ì§€(ë³‘ë™)ë¡œ í•„í„°", ward_options, index=0, key="ward_coach")
    with opt_col2:
        btn_next = st.button("ë‹¤ìŒ ë¬¸ì œ")
    with opt_col3:
        btn_rand = st.button("ëœë¤ ì¶œì œ")
    with opt_col4:
        tiles = st.slider("ë²„íŠ¼ í‘œì‹œ ê°œìˆ˜", 6, 48, 18, 3, key="coach_tiles")

    filtered_catalog = get_filtered_catalog(catalog, st.session_state.get("ward_coach","ì „ì²´"))
    st.caption(f"ê°€ìš© ë¬¸í•­: {0 if filtered_catalog is None else len(filtered_catalog)}ê°œ")

    rebuild_order_if_needed(filtered_catalog, shuffle=False, ward_choice=st.session_state.get("ward_coach","ì „ì²´"), mode_tag="coach")

    if btn_next: next_case(filtered_catalog)
    if btn_rand: random_case(filtered_catalog)
    ensure_case_selected(filtered_catalog)

    chosen = render_case_shelf(filtered_catalog, label="ë‹¤ë¥¸ ì¼€ì´ìŠ¤ ì„ íƒ", max_items=tiles)
    if chosen is not None:
        sheet = st.session_state.get("active_sheet") or str(df_embed["sheet"].iloc[0])
        st.session_state["last_topk"] = select_case_by_row(df_embed, sheet, chosen)
        st.session_state["last_topk_source"] = "coach_select"
        reset_reveal_flags()

    if st.session_state["last_topk"] is not None and len(st.session_state["last_topk"])>0:
        top1 = st.session_state["last_topk"].iloc[0]
        show_case_header(top1, reveal_answer=st.session_state["revealed_coach"])

        st.caption("í›ˆë ¨ìƒì˜ ì´ˆì•ˆ ë¬¸ì¥ì„ ì½”ì¹­í•©ë‹ˆë‹¤. ì œì¶œ í›„ ì •ë‹µì´ ê³µê°œë©ë‹ˆë‹¤.")
        with st.form("coach_form", clear_on_submit=False):
            tone = st.selectbox("ì½”ì¹­ í†¤", ["ë”°ëœ»í•˜ê³  ì •ì¤‘í•˜ê²Œ","ê°„ê²°í•˜ê³  ë‹¨í˜¸í•˜ê²Œ","ì°¨ë¶„í•˜ê³  ê³µê° ìˆê²Œ"], index=0)
            user_answer = st.text_area("í›ˆë ¨ìƒ ì´ˆì•ˆ(í˜„ì¬ ë§í•˜ë ¤ëŠ” ë¬¸ì¥)", value=st.session_state.get("draft_text",""), height=140, key="draft_area")
            colA, colB = st.columns(2)
            with colA:
                if st.session_state.get("revealed_coach"):
                    auto_draft = st.form_submit_button("ì´ˆì•ˆ ìë™ ì œì‹œ")
                else:
                    st.caption("ì´ˆì•ˆ ìë™ ì œì‹œëŠ” ì •ë‹µ ê³µê°œ í›„ ì‚¬ìš© ê°€ëŠ¥"); auto_draft = False
            with colB:
                btn_coach = st.form_submit_button("ì½”ì¹­ ë°›ê¸°")

        if 'auto_draft' in locals() and auto_draft:
            msgs_draft = [
                {"role":"system","content":f"ê°„í˜¸ì‚¬ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì½”ì¹˜ì…ë‹ˆë‹¤. ê·¼ë¬´ì§€: {workplace}. í‘œì¤€ì‘ë‹µì„ ì°¸ê³ í•´ í•œêµ­ì–´ë¡œ 1~2ë¬¸ì¥ ì •ì¤‘í•œ ì•ˆë‚´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”."},
                {"role":"user","content": f"[í‘œì¤€ì‘ë‹µ]\n{top1['answer']}\n\nì¶œë ¥: ê³µì†í•˜ê³  ëª…í™•í•œ 1~2ë¬¸ì¥"}
            ]
            draft_text = call_llm(msgs_draft, max_output_tokens=200, temperature=0.2)
            st.session_state["draft_text"] = draft_text
            st.experimental_rerun()

        if btn_coach:
            base_text = (user_answer or "").strip() or (st.session_state.get("draft_text","") or "").strip()
            msgs = make_messages_for_coach(top1, base_text, workplace, tone, forb_prompt)
            coaching = call_llm(msgs, max_output_tokens=1200, temperature=0.25)
            st.session_state["coaching_text"] = coaching
            st.markdown("### ğŸ§‘â€ğŸ« ì½”ì¹­ ê²°ê³¼"); st.write(coaching)
            st.session_state["revealed_coach"] = True
            with st.expander("ì •ë‹µ(í‘œì¤€ì‘ë‹µ) ë³´ê¸°", expanded=True):
                st.write(top1["answer"])

        if st.session_state.get("coaching_text"):
            st.divider()
            st.markdown("### âœï¸ ë‹¤ì‹œ ì¨ë³´ê¸° â†’ ì¬ì½”ì¹­")
            revised = st.text_area("ìˆ˜ì •ì•ˆ(ì½”ì¹­ì„ ë°˜ì˜í•´ ë‹¤ì‹œ ì‘ì„±)", height=140, key="revised_text")
            if st.button("ë‹¤ì‹œ ì½”ì¹­"):
                msgs2 = make_messages_for_coach(top1, (revised or "").strip(), workplace, tone, forb_prompt)
                coaching2 = call_llm(msgs2, max_output_tokens=1200, temperature=0.25)
                st.session_state["coaching_text"] = coaching2
                st.markdown("### ğŸ§‘â€ğŸ« ì¬ì½”ì¹­ ê²°ê³¼"); st.write(coaching2)
    else:
        st.warning("ì¼€ì´ìŠ¤ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ì„ë² ë”©ì„ ì¤€ë¹„í•´ ì£¼ì„¸ìš”.")